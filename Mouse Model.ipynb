{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be26b8c2-01b5-4333-88fb-9c7c68c6c41e",
   "metadata": {},
   "source": [
    "## Promoter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4181e4c1-81a1-4792-bcbb-0c166de965e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv('/home/ykq/projects/CPSC0926/mouse/all_dna.csv')\n",
    "promoter_df = df[df['wghmm.state.type'] == 'Promoter'].copy()\n",
    "\n",
    "promoter_df['center'] = (promoter_df['wghmm.start'] + promoter_df['wghmm.end']) / 2\n",
    "promoter_df['start'] = promoter_df['center'].astype(int) - 1000\n",
    "promoter_df['end'] = promoter_df['center'].astype(int) + 1000\n",
    "\n",
    "# 创建newID\n",
    "promoter_df['newID'] = promoter_df['wghmm.chr'] + '-' + promoter_df['start'].astype(str) + '-' + promoter_df['end'].astype(str)\n",
    "target_strings = promoter_df['newID'].tolist()\n",
    "\n",
    "# 读取另一个文件并筛选\n",
    "df2 = pd.read_csv('/home/ykq/projects/CPSC0926/mouse/traindata.csv')\n",
    "filtered_df2 = df2[df2['ID'].isin(target_strings)]\n",
    "os.makedirs('/home/ykq/projects/CPSC0926/mouse/train', exist_ok=True)\n",
    "os.makedirs('/home/ykq/projects/CPSC0926/mouse/train/P', exist_ok=True)\n",
    "# 保存筛选结果\n",
    "filtered_df2.to_csv('/home/ykq/projects/CPSC0926/mouse/train/P/traindata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f5633b-615b-405f-9979-a4013f01c82f",
   "metadata": {},
   "source": [
    "## Labeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b58ed0ce-cf0f-4bb0-961c-6b29ca3ae377",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T03:13:38.084912Z",
     "start_time": "2025-09-09T03:13:35.272885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 读取数据\n",
    "p_dna = pd.read_csv('/home/ykq/projects/CPSC0926/mouse/all_dna.csv')\n",
    "train_data = pd.read_csv('/home/ykq/projects/CPSC0926/mouse/train/P/traindata.csv')\n",
    "\n",
    "'''\n",
    "方法一：按照baseMean的20%取cutoff，HCP和MCP做正样本，LCP做负样本\n",
    "方法二：按照baseMean的20%取cutoff，HCP做正样本，LCP和MCP做负样本\n",
    "方法三：按照baseMean的20%取cutoff，HCP做正样本，LCP做负样本,观察MCP的分布\n",
    "'''\n",
    "\n",
    "# 方法一\n",
    "# filtered_p_dna_1 = p_dna[(p_dna['pstype'].isin(['HCP', 'MCP'])) & (p_dna['baseMean'] >= p_dna['baseMean'].quantile(0.2))].copy()\n",
    "# filtered_p_dna_2 = p_dna[(p_dna['pstype'] == 'LCP') & (p_dna['baseMean'] >= p_dna['baseMean'].quantile(0.2))].copy()\n",
    "\n",
    "# 方法二\n",
    "# filtered_p_dna_1 = p_dna[(p_dna['pstype'].isin(['HCP'])) & (p_dna['baseMean'] >= p_dna['baseMean'].quantile(0.2))].copy()\n",
    "# filtered_p_dna_2 = p_dna[(p_dna['pstype'].isin(['LCP', 'MCP'])) & (p_dna['baseMean'] >= p_dna['baseMean'].quantile(0.2))].copy()\n",
    "\n",
    "# 方法三\n",
    "filtered_p_dna_1 = p_dna[(p_dna['pstype'].isin(['HCP']))].copy()\n",
    "filtered_p_dna_2 = p_dna[(p_dna['pstype'].isin(['LCP']))].copy()\n",
    "\n",
    "# 处理条件1的数据\n",
    "filtered_p_dna_1.loc[:, 'center'] = (filtered_p_dna_1['wghmm.start'] + filtered_p_dna_1['wghmm.end']) / 2\n",
    "filtered_p_dna_1.loc[:, 'start'] = filtered_p_dna_1['center'].astype(int) - 1000\n",
    "filtered_p_dna_1.loc[:, 'end'] = filtered_p_dna_1['center'].astype(int) + 1000\n",
    "filtered_p_dna_1.loc[:, 'newID'] = filtered_p_dna_1['wghmm.chr']+'-'+filtered_p_dna_1['start'].astype(str)+'-'+filtered_p_dna_1['end'].astype(str)\n",
    "\n",
    "# 处理条件2的数据\n",
    "filtered_p_dna_2.loc[:, 'center'] = (filtered_p_dna_2['wghmm.start'] + filtered_p_dna_2['wghmm.end']) / 2\n",
    "filtered_p_dna_2.loc[:, 'start'] = filtered_p_dna_2['center'].astype(int) - 1000\n",
    "filtered_p_dna_2.loc[:, 'end'] = filtered_p_dna_2['center'].astype(int) + 1000\n",
    "filtered_p_dna_2.loc[:, 'newID'] = filtered_p_dna_2['wghmm.chr']+'-'+filtered_p_dna_2['start'].astype(str)+'-'+filtered_p_dna_2['end'].astype(str)\n",
    "\n",
    "# 获取两种条件下的目标字符串\n",
    "target_strings_1 = filtered_p_dna_1['newID'].tolist()\n",
    "target_strings_2 = filtered_p_dna_2['newID'].tolist()\n",
    "\n",
    "# 修改traindata.csv文件中Y列的值\n",
    "train_data.loc[\n",
    "    (train_data['chromosome'].isin(filtered_p_dna_1['wghmm.chr'])) &\n",
    "    (train_data['start'].isin(filtered_p_dna_1['start'])) &\n",
    "    (train_data['end'].isin(filtered_p_dna_1['end'])) &\n",
    "    (train_data['ID'].isin(target_strings_1)),\n",
    "    'Y'\n",
    "] = 1\n",
    "\n",
    "train_data.loc[\n",
    "    (train_data['chromosome'].isin(filtered_p_dna_2['wghmm.chr'])) &\n",
    "    (train_data['start'].isin(filtered_p_dna_2['start'])) &\n",
    "    (train_data['end'].isin(filtered_p_dna_2['end'])) &\n",
    "    (train_data['ID'].isin(target_strings_2)),\n",
    "    'Y'\n",
    "] = 2\n",
    "\n",
    "# 保存修改后的文件\n",
    "train_data.to_csv('/home/ykq/projects/CPSC0926/mouse/train/P/traindata_withlabel1.csv', index=False)\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fe3ace8e-5852-48cd-996d-4c46c62a14f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/ykq/projects/CPSC0926/mouse/train/P/traindata_withlabel1.csv')\n",
    "df_selected = df[df['Y'].isin([1, 2])]\n",
    "#df_selected = df[df['Y'].isin([0, 1, 2])]\n",
    "# 创建新文件夹\n",
    "# os.makedirs('/home/ykq/projects/CPSC/K562/train/traintest/2', exist_ok=True)\n",
    "df_selected.loc[df_selected['Y'] == 2, 'Y'] = 0\n",
    "\n",
    "# 保存新的CSV文件\n",
    "df_selected.to_csv('/home/ykq/projects/CPSC0926/mouse/train/P/traindata_withlabel.csv', index=False)\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70316b6-4bfb-4e29-a3c2-7eb61a933473",
   "metadata": {},
   "source": [
    "## Train, valid and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6687d76c-9535-4d0b-bca3-5c870027982c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据处理完成，文件已保存。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "change_dir='P'\n",
    "# 读取数据\n",
    "file_path =f'/home/ykq/projects/CPSC0926/mouse/train/{change_dir}/traindata_withlabel.csv'  # 替换为你的文件路径\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 根据 8:1:1 拆分数据\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.1, random_state=42)  # 20% 测试集\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.111, random_state=42)  # 25% 测试集 -> 20% 总数据集\n",
    "\n",
    "# 创建输出目录\n",
    "output_dir = f'/home/ykq/projects/CPSC0926/mouse/train/{change_dir}/traindata'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 保存文件\n",
    "train_df.to_csv(os.path.join(output_dir, 'train.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(output_dir, 'test.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(output_dir, 'val.csv'), index=False)\n",
    "\n",
    "print(\"数据处理完成，文件已保存。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2637d6-5b37-493d-9564-ff94f2ecff12",
   "metadata": {},
   "source": [
    "## 运行下面这个代码的时候，现在默认是阳性样本点少于阴性样本点，如果报错就交换一下，用注释内的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9b3442fd-7a61-4626-a6f0-888a8afda9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将平衡后的数据保存到: /home/ykq/projects/CPSC0926/mouse/train/P/traindata/equaltrain.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "change_dir='P'\n",
    "def downsample_dataframe(file_path, target_column='Y'):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    #阳性样本点大于阴性样本点\n",
    "    df_minority = df[df[target_column] == 0]\n",
    "    df_majority = df[df[target_column] == 1]\n",
    "    #阳性样本点小于阴性样本点\n",
    "    # df_minority = df[df[target_column] == 1]\n",
    "    # df_majority = df[df[target_column] == 0]\n",
    "    \n",
    "    df_majority_downsampled = df_majority.sample(n=len(df_minority), random_state=42)\n",
    "    df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "    # --- 6. (重要步骤) 打乱整个数据集的顺序 ---\n",
    "    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    return df_balanced\n",
    "\n",
    "# --- 主程序入口 ---\n",
    "if __name__ == '__main__':\n",
    "    input_file = f'/home/ykq/projects/CPSC0926/mouse/train/{change_dir}/traindata/train.csv'\n",
    "    output_file = f'/home/ykq/projects/CPSC0926/mouse/train/{change_dir}/traindata/equaltrain.csv'\n",
    "    balanced_df = downsample_dataframe(input_file, target_column='Y')\n",
    "    balanced_df.to_csv(output_file, index=False)\n",
    "    print(f\"已将平衡后的数据保存到: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8c6587c7-58ab-4c95-869c-d8ab73b57379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equaltrain 数据 shape=(7540, 19, 24), 标签 length=7540\n",
      "\n",
      "val 数据 shape=(948, 19, 24), 标签 length=948\n",
      "\n",
      "test 数据 shape=(949, 19, 24), 标签 length=949\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "change_dir='P'\n",
    "# 参数配置\n",
    "# 单细胞数据\n",
    "input_dir = '/home/ykq/projects/CPSC0926/mouse/features/'  # .npy文件存放目录\n",
    "# bulk数据\n",
    "# input_dir = '/home/ykq/projects/CPSC/0922/GM12878/features/'  # .npy文件存放目录\n",
    "labels_csv = f'/home/ykq/projects/CPSC0926/mouse/train/{change_dir}/traindata_withlabel.csv'  # CSV文件路径\n",
    "output_dir = f'/home/ykq/projects/CPSC0926/mouse/train/{change_dir}/traindata'  # 输出路径\n",
    "\n",
    "# 创建输出目录\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 加载标签数据\n",
    "labels_df = pd.read_csv(labels_csv)\n",
    "\n",
    "# 循环处理 train、val 和 test 数据\n",
    "for split_name in [\"equaltrain\", \"val\", \"test\"]:\n",
    "    # 读取对应的 CSV 文件\n",
    "    split_file_path = os.path.join(output_dir, f'{split_name}.csv')\n",
    "    split_df = pd.read_csv(split_file_path)\n",
    "\n",
    "    data_list = []\n",
    "    labels = []\n",
    "\n",
    "    # 遍历每一行，加载对应的 NPY 数据文件\n",
    "    for index, row in split_df.iterrows():\n",
    "        file_id = row['ID']  # 获取文件ID （假设ID列名为 'ID'）\n",
    "        label = row['Y']  # 获取标签 （假设Y列名为 'Y'）\n",
    "\n",
    "        # 加载对应的 NPY 文件\n",
    "        npy_file_path = os.path.join(input_dir, f\"{file_id}.npy\")\n",
    "        if os.path.exists(npy_file_path):\n",
    "            matrix = np.load(npy_file_path)  # 加载 .npy 数据\n",
    "            data_list.append(matrix)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"未找到文件：{npy_file_path}\")\n",
    "\n",
    "    # 转为 numpy 数组\n",
    "    data_array = np.stack(data_list, axis=0)\n",
    "    labels_array = np.array(labels)\n",
    "\n",
    "    # 保存为 .npz 文件\n",
    "    np.savez(os.path.join(output_dir, f\"{split_name}_data.npz\"), data=data_array)\n",
    "    np.savez(os.path.join(output_dir, f\"{split_name}_labels.npz\"), labels=labels_array)\n",
    "\n",
    "    print(f\"{split_name} 数据 shape={data_array.shape}, 标签 length={len(labels_array)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c062c3-8ac1-409e-86e3-7c7b0562d2ec",
   "metadata": {},
   "source": [
    "## 带ATAC的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fdea7668-deaf-4d7e-83ad-0282eb3f6959",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Current LR: 0.000500\n",
      "Epoch 1/200\n",
      "Train Loss: 0.0867, Train Accuracy: 49.39%\n",
      "Val Loss: 0.0866, Val Accuracy: 51.27%\n",
      "Epoch 2, Current LR: 0.000500\n",
      "Epoch 2/200\n",
      "Train Loss: 0.0866, Train Accuracy: 49.52%\n",
      "Val Loss: 0.0865, Val Accuracy: 57.81%\n",
      "Epoch 3, Current LR: 0.000500\n",
      "Epoch 3/200\n",
      "Train Loss: 0.0859, Train Accuracy: 56.91%\n",
      "Val Loss: 0.0852, Val Accuracy: 56.22%\n",
      "Epoch 4, Current LR: 0.000500\n",
      "Epoch 4/200\n",
      "Train Loss: 0.0838, Train Accuracy: 61.05%\n",
      "Val Loss: 0.0822, Val Accuracy: 63.29%\n",
      "Epoch 5, Current LR: 0.000500\n",
      "Epoch 5/200\n",
      "Train Loss: 0.0809, Train Accuracy: 63.10%\n",
      "Val Loss: 0.0792, Val Accuracy: 65.19%\n",
      "Epoch 6, Current LR: 0.000500\n",
      "Epoch 6/200\n",
      "Train Loss: 0.0790, Train Accuracy: 64.67%\n",
      "Val Loss: 0.0763, Val Accuracy: 65.93%\n",
      "Epoch 7, Current LR: 0.000500\n",
      "Epoch 7/200\n",
      "Train Loss: 0.0777, Train Accuracy: 65.56%\n",
      "Val Loss: 0.0764, Val Accuracy: 67.09%\n",
      "Epoch 8, Current LR: 0.000500\n",
      "Epoch 8/200\n",
      "Train Loss: 0.0773, Train Accuracy: 66.23%\n",
      "Val Loss: 0.0756, Val Accuracy: 67.09%\n",
      "Epoch 9, Current LR: 0.000500\n",
      "Epoch 9/200\n",
      "Train Loss: 0.0770, Train Accuracy: 65.86%\n",
      "Val Loss: 0.0759, Val Accuracy: 68.25%\n",
      "Epoch 10, Current LR: 0.000500\n",
      "Epoch 10/200\n",
      "Train Loss: 0.0766, Train Accuracy: 66.84%\n",
      "Val Loss: 0.0751, Val Accuracy: 67.83%\n",
      "Epoch 11, Current LR: 0.000500\n",
      "Epoch 11/200\n",
      "Train Loss: 0.0764, Train Accuracy: 66.84%\n",
      "Val Loss: 0.0749, Val Accuracy: 68.46%\n",
      "Epoch 12, Current LR: 0.000500\n",
      "Epoch 12/200\n",
      "Train Loss: 0.0764, Train Accuracy: 66.25%\n",
      "Val Loss: 0.0750, Val Accuracy: 68.78%\n",
      "Epoch 13, Current LR: 0.000500\n",
      "Epoch 13/200\n",
      "Train Loss: 0.0757, Train Accuracy: 67.11%\n",
      "Val Loss: 0.0744, Val Accuracy: 68.35%\n",
      "Epoch 14, Current LR: 0.000500\n",
      "Epoch 14/200\n",
      "Train Loss: 0.0750, Train Accuracy: 67.65%\n",
      "Val Loss: 0.0744, Val Accuracy: 68.35%\n",
      "Epoch 15, Current LR: 0.000500\n",
      "Epoch 15/200\n",
      "Train Loss: 0.0744, Train Accuracy: 68.45%\n",
      "Val Loss: 0.0739, Val Accuracy: 68.99%\n",
      "Epoch 16, Current LR: 0.000500\n",
      "Epoch 16/200\n",
      "Train Loss: 0.0741, Train Accuracy: 68.93%\n",
      "Val Loss: 0.0737, Val Accuracy: 69.83%\n",
      "Epoch 17, Current LR: 0.000500\n",
      "Epoch 17/200\n",
      "Train Loss: 0.0736, Train Accuracy: 69.60%\n",
      "Val Loss: 0.0733, Val Accuracy: 69.83%\n",
      "Epoch 18, Current LR: 0.000500\n",
      "Epoch 18/200\n",
      "Train Loss: 0.0735, Train Accuracy: 68.95%\n",
      "Val Loss: 0.0736, Val Accuracy: 69.20%\n",
      "Epoch 19, Current LR: 0.000500\n",
      "Epoch 19/200\n",
      "Train Loss: 0.0733, Train Accuracy: 69.62%\n",
      "Val Loss: 0.0729, Val Accuracy: 69.30%\n",
      "Epoch 20, Current LR: 0.000500\n",
      "Epoch 20/200\n",
      "Train Loss: 0.0724, Train Accuracy: 70.42%\n",
      "Val Loss: 0.0731, Val Accuracy: 69.41%\n",
      "Epoch 21, Current LR: 0.000500\n",
      "Epoch 21/200\n",
      "Train Loss: 0.0725, Train Accuracy: 70.09%\n",
      "Val Loss: 0.0728, Val Accuracy: 69.62%\n",
      "Epoch 22, Current LR: 0.000500\n",
      "Epoch 22/200\n",
      "Train Loss: 0.0720, Train Accuracy: 70.49%\n",
      "Val Loss: 0.0724, Val Accuracy: 69.83%\n",
      "Epoch 23, Current LR: 0.000500\n",
      "Epoch 23/200\n",
      "Train Loss: 0.0715, Train Accuracy: 70.11%\n",
      "Val Loss: 0.0722, Val Accuracy: 69.83%\n",
      "Epoch 24, Current LR: 0.000500\n",
      "Epoch 24/200\n",
      "Train Loss: 0.0718, Train Accuracy: 70.03%\n",
      "Val Loss: 0.0727, Val Accuracy: 69.20%\n",
      "Epoch 25, Current LR: 0.000500\n",
      "Epoch 25/200\n",
      "Train Loss: 0.0710, Train Accuracy: 70.94%\n",
      "Val Loss: 0.0721, Val Accuracy: 70.36%\n",
      "Epoch 26, Current LR: 0.000500\n",
      "Epoch 26/200\n",
      "Train Loss: 0.0710, Train Accuracy: 70.98%\n",
      "Val Loss: 0.0717, Val Accuracy: 71.62%\n",
      "Epoch 27, Current LR: 0.000500\n",
      "Epoch 27/200\n",
      "Train Loss: 0.0705, Train Accuracy: 70.90%\n",
      "Val Loss: 0.0713, Val Accuracy: 71.31%\n",
      "Epoch 28, Current LR: 0.000500\n",
      "Epoch 28/200\n",
      "Train Loss: 0.0704, Train Accuracy: 71.55%\n",
      "Val Loss: 0.0708, Val Accuracy: 72.05%\n",
      "Epoch 29, Current LR: 0.000500\n",
      "Epoch 29/200\n",
      "Train Loss: 0.0700, Train Accuracy: 71.17%\n",
      "Val Loss: 0.0705, Val Accuracy: 71.94%\n",
      "Epoch 30, Current LR: 0.000500\n",
      "Epoch 30/200\n",
      "Train Loss: 0.0697, Train Accuracy: 71.56%\n",
      "Val Loss: 0.0704, Val Accuracy: 72.26%\n",
      "Epoch 31, Current LR: 0.000500\n",
      "Epoch 31/200\n",
      "Train Loss: 0.0693, Train Accuracy: 71.94%\n",
      "Val Loss: 0.0699, Val Accuracy: 72.57%\n",
      "Epoch 32, Current LR: 0.000500\n",
      "Epoch 32/200\n",
      "Train Loss: 0.0690, Train Accuracy: 71.75%\n",
      "Val Loss: 0.0699, Val Accuracy: 73.21%\n",
      "Epoch 33, Current LR: 0.000500\n",
      "Epoch 33/200\n",
      "Train Loss: 0.0691, Train Accuracy: 71.96%\n",
      "Val Loss: 0.0699, Val Accuracy: 73.31%\n",
      "Epoch 34, Current LR: 0.000500\n",
      "Epoch 34/200\n",
      "Train Loss: 0.0688, Train Accuracy: 72.47%\n",
      "Val Loss: 0.0691, Val Accuracy: 73.10%\n",
      "Epoch 35, Current LR: 0.000500\n",
      "Epoch 35/200\n",
      "Train Loss: 0.0682, Train Accuracy: 72.56%\n",
      "Val Loss: 0.0690, Val Accuracy: 72.36%\n",
      "Epoch 36, Current LR: 0.000500\n",
      "Epoch 36/200\n",
      "Train Loss: 0.0681, Train Accuracy: 72.27%\n",
      "Val Loss: 0.0685, Val Accuracy: 72.89%\n",
      "Epoch 37, Current LR: 0.000500\n",
      "Epoch 37/200\n",
      "Train Loss: 0.0679, Train Accuracy: 72.45%\n",
      "Val Loss: 0.0685, Val Accuracy: 73.63%\n",
      "Epoch 38, Current LR: 0.000500\n",
      "Epoch 38/200\n",
      "Train Loss: 0.0676, Train Accuracy: 72.98%\n",
      "Val Loss: 0.0683, Val Accuracy: 72.68%\n",
      "Epoch 39, Current LR: 0.000500\n",
      "Epoch 39/200\n",
      "Train Loss: 0.0671, Train Accuracy: 72.97%\n",
      "Val Loss: 0.0681, Val Accuracy: 73.84%\n",
      "Epoch 40, Current LR: 0.000500\n",
      "Epoch 40/200\n",
      "Train Loss: 0.0667, Train Accuracy: 73.12%\n",
      "Val Loss: 0.0682, Val Accuracy: 73.52%\n",
      "Epoch 41, Current LR: 0.000500\n",
      "Epoch 41/200\n",
      "Train Loss: 0.0674, Train Accuracy: 73.08%\n",
      "Val Loss: 0.0690, Val Accuracy: 71.73%\n",
      "Epoch 42, Current LR: 0.000500\n",
      "Epoch 42/200\n",
      "Train Loss: 0.0670, Train Accuracy: 72.94%\n",
      "Val Loss: 0.0686, Val Accuracy: 72.89%\n",
      "Epoch 43, Current LR: 0.000500\n",
      "Epoch 43/200\n",
      "Train Loss: 0.0667, Train Accuracy: 73.28%\n",
      "Val Loss: 0.0679, Val Accuracy: 73.42%\n",
      "Epoch 44, Current LR: 0.000500\n",
      "Epoch 44/200\n",
      "Train Loss: 0.0664, Train Accuracy: 73.33%\n",
      "Val Loss: 0.0677, Val Accuracy: 73.21%\n",
      "Epoch 45, Current LR: 0.000500\n",
      "Epoch 45/200\n",
      "Train Loss: 0.0669, Train Accuracy: 73.59%\n",
      "Val Loss: 0.0684, Val Accuracy: 72.89%\n",
      "Epoch 46, Current LR: 0.000500\n",
      "Epoch 46/200\n",
      "Train Loss: 0.0666, Train Accuracy: 73.04%\n",
      "Val Loss: 0.0675, Val Accuracy: 73.52%\n",
      "Epoch 47, Current LR: 0.000500\n",
      "Epoch 47/200\n",
      "Train Loss: 0.0663, Train Accuracy: 73.61%\n",
      "Val Loss: 0.0678, Val Accuracy: 73.63%\n",
      "Epoch 48, Current LR: 0.000500\n",
      "Epoch 48/200\n",
      "Train Loss: 0.0668, Train Accuracy: 73.18%\n",
      "Val Loss: 0.0680, Val Accuracy: 73.00%\n",
      "Epoch 49, Current LR: 0.000500\n",
      "Epoch 49/200\n",
      "Train Loss: 0.0664, Train Accuracy: 73.32%\n",
      "Val Loss: 0.0674, Val Accuracy: 74.58%\n",
      "Epoch 50, Current LR: 0.000500\n",
      "Epoch 50/200\n",
      "Train Loss: 0.0665, Train Accuracy: 73.30%\n",
      "Val Loss: 0.0676, Val Accuracy: 74.16%\n",
      "Epoch 51, Current LR: 0.000500\n",
      "Epoch 51/200\n",
      "Train Loss: 0.0663, Train Accuracy: 73.73%\n",
      "Val Loss: 0.0682, Val Accuracy: 73.00%\n",
      "Epoch 52, Current LR: 0.000500\n",
      "Epoch 52/200\n",
      "Train Loss: 0.0662, Train Accuracy: 73.41%\n",
      "Val Loss: 0.0672, Val Accuracy: 74.47%\n",
      "Epoch 53, Current LR: 0.000500\n",
      "Epoch 53/200\n",
      "Train Loss: 0.0661, Train Accuracy: 73.36%\n",
      "Val Loss: 0.0676, Val Accuracy: 74.37%\n",
      "Epoch 54, Current LR: 0.000500\n",
      "Epoch 54/200\n",
      "Train Loss: 0.0662, Train Accuracy: 73.83%\n",
      "Val Loss: 0.0677, Val Accuracy: 73.52%\n",
      "Epoch 55, Current LR: 0.000500\n",
      "Epoch 55/200\n",
      "Train Loss: 0.0660, Train Accuracy: 73.85%\n",
      "Val Loss: 0.0678, Val Accuracy: 73.73%\n",
      "Epoch 56, Current LR: 0.000500\n",
      "Epoch 56/200\n",
      "Train Loss: 0.0658, Train Accuracy: 73.46%\n",
      "Val Loss: 0.0676, Val Accuracy: 73.84%\n",
      "Epoch 57, Current LR: 0.000500\n",
      "Epoch 57/200\n",
      "Train Loss: 0.0656, Train Accuracy: 74.35%\n",
      "Val Loss: 0.0675, Val Accuracy: 73.63%\n",
      "Epoch 58, Current LR: 0.000500\n",
      "Epoch 58/200\n",
      "Train Loss: 0.0656, Train Accuracy: 73.82%\n",
      "Val Loss: 0.0669, Val Accuracy: 75.53%\n",
      "Epoch 59, Current LR: 0.000500\n",
      "Epoch 59/200\n",
      "Train Loss: 0.0658, Train Accuracy: 73.86%\n",
      "Val Loss: 0.0678, Val Accuracy: 73.63%\n",
      "Epoch 60, Current LR: 0.000500\n",
      "Epoch 60/200\n",
      "Train Loss: 0.0658, Train Accuracy: 73.78%\n",
      "Val Loss: 0.0673, Val Accuracy: 74.05%\n",
      "Epoch 61, Current LR: 0.000500\n",
      "Epoch 61/200\n",
      "Train Loss: 0.0653, Train Accuracy: 73.55%\n",
      "Val Loss: 0.0674, Val Accuracy: 74.26%\n",
      "Epoch 62, Current LR: 0.000500\n",
      "Epoch 62/200\n",
      "Train Loss: 0.0658, Train Accuracy: 74.02%\n",
      "Val Loss: 0.0675, Val Accuracy: 74.05%\n",
      "Epoch 63, Current LR: 0.000500\n",
      "Epoch 63/200\n",
      "Train Loss: 0.0656, Train Accuracy: 73.75%\n",
      "Val Loss: 0.0677, Val Accuracy: 73.73%\n",
      "Epoch 64, Current LR: 0.000500\n",
      "Epoch 64/200\n",
      "Train Loss: 0.0652, Train Accuracy: 73.69%\n",
      "Val Loss: 0.0673, Val Accuracy: 75.00%\n",
      "Epoch 65, Current LR: 0.000500\n",
      "Epoch 65/200\n",
      "Train Loss: 0.0658, Train Accuracy: 74.02%\n",
      "Val Loss: 0.0671, Val Accuracy: 74.05%\n",
      "Epoch 66, Current LR: 0.000500\n",
      "Epoch 66/200\n",
      "Train Loss: 0.0657, Train Accuracy: 73.99%\n",
      "Val Loss: 0.0689, Val Accuracy: 72.05%\n",
      "Epoch 67, Current LR: 0.000500\n",
      "Epoch 67/200\n",
      "Train Loss: 0.0656, Train Accuracy: 73.36%\n",
      "Val Loss: 0.0678, Val Accuracy: 73.63%\n",
      "Epoch 68, Current LR: 0.000500\n",
      "Epoch 68/200\n",
      "Train Loss: 0.0654, Train Accuracy: 73.70%\n",
      "Val Loss: 0.0670, Val Accuracy: 74.58%\n",
      "Epoch 69, Current LR: 0.000500\n",
      "Epoch 69/200\n",
      "Train Loss: 0.0657, Train Accuracy: 73.98%\n",
      "Val Loss: 0.0704, Val Accuracy: 71.10%\n",
      "Epoch 70, Current LR: 0.000500\n",
      "Epoch 70/200\n",
      "Train Loss: 0.0660, Train Accuracy: 73.91%\n",
      "Val Loss: 0.0671, Val Accuracy: 74.68%\n",
      "Epoch 71, Current LR: 0.000500\n",
      "Epoch 71/200\n",
      "Train Loss: 0.0654, Train Accuracy: 74.02%\n",
      "Val Loss: 0.0669, Val Accuracy: 74.79%\n",
      "Epoch 72, Current LR: 0.000500\n",
      "Epoch 72/200\n",
      "Train Loss: 0.0653, Train Accuracy: 73.98%\n",
      "Val Loss: 0.0673, Val Accuracy: 73.95%\n",
      "Epoch 73, Current LR: 0.000500\n",
      "Epoch 73/200\n",
      "Train Loss: 0.0654, Train Accuracy: 74.44%\n",
      "Val Loss: 0.0670, Val Accuracy: 75.32%\n",
      "Epoch 74, Current LR: 0.000500\n",
      "Epoch 74/200\n",
      "Train Loss: 0.0651, Train Accuracy: 74.05%\n",
      "Val Loss: 0.0674, Val Accuracy: 73.73%\n",
      "Epoch 75, Current LR: 0.000500\n",
      "Epoch 75/200\n",
      "Train Loss: 0.0652, Train Accuracy: 74.30%\n",
      "Val Loss: 0.0675, Val Accuracy: 73.21%\n",
      "Epoch 76, Current LR: 0.000500\n",
      "Epoch 76/200\n",
      "Train Loss: 0.0654, Train Accuracy: 74.39%\n",
      "Val Loss: 0.0668, Val Accuracy: 74.79%\n",
      "Epoch 77, Current LR: 0.000500\n",
      "Epoch 77/200\n",
      "Train Loss: 0.0652, Train Accuracy: 73.98%\n",
      "Val Loss: 0.0669, Val Accuracy: 74.26%\n",
      "Epoch 78, Current LR: 0.000500\n",
      "Epoch 78/200\n",
      "Train Loss: 0.0651, Train Accuracy: 74.22%\n",
      "Val Loss: 0.0674, Val Accuracy: 73.52%\n",
      "Epoch 79, Current LR: 0.000500\n",
      "Epoch 79/200\n",
      "Train Loss: 0.0651, Train Accuracy: 74.16%\n",
      "Val Loss: 0.0669, Val Accuracy: 74.79%\n",
      "Epoch 80, Current LR: 0.000500\n",
      "Epoch 80/200\n",
      "Train Loss: 0.0651, Train Accuracy: 73.99%\n",
      "Val Loss: 0.0675, Val Accuracy: 74.37%\n",
      "Epoch 81, Current LR: 0.000500\n",
      "Epoch 81/200\n",
      "Train Loss: 0.0653, Train Accuracy: 73.95%\n",
      "Val Loss: 0.0681, Val Accuracy: 72.89%\n",
      "Epoch 82, Current LR: 0.000500\n",
      "Epoch 82/200\n",
      "Train Loss: 0.0649, Train Accuracy: 73.94%\n",
      "Val Loss: 0.0696, Val Accuracy: 71.62%\n",
      "Epoch 83, Current LR: 0.000500\n",
      "Epoch 83/200\n",
      "Train Loss: 0.0652, Train Accuracy: 74.31%\n",
      "Val Loss: 0.0674, Val Accuracy: 73.42%\n",
      "Epoch 84, Current LR: 0.000500\n",
      "Epoch 84/200\n",
      "Train Loss: 0.0650, Train Accuracy: 73.94%\n",
      "Val Loss: 0.0679, Val Accuracy: 73.63%\n",
      "Epoch 85, Current LR: 0.000500\n",
      "Epoch 85/200\n",
      "Train Loss: 0.0653, Train Accuracy: 73.79%\n",
      "Val Loss: 0.0680, Val Accuracy: 73.31%\n",
      "Epoch 86, Current LR: 0.000500\n",
      "Epoch 86/200\n",
      "Train Loss: 0.0651, Train Accuracy: 74.10%\n",
      "Val Loss: 0.0667, Val Accuracy: 75.00%\n",
      "Epoch 87, Current LR: 0.000500\n",
      "Epoch 87/200\n",
      "Train Loss: 0.0652, Train Accuracy: 73.78%\n",
      "Val Loss: 0.0696, Val Accuracy: 70.99%\n",
      "Epoch 88, Current LR: 0.000500\n",
      "Epoch 88/200\n",
      "Train Loss: 0.0648, Train Accuracy: 73.83%\n",
      "Val Loss: 0.0689, Val Accuracy: 72.36%\n",
      "Epoch 89, Current LR: 0.000500\n",
      "Epoch 89/200\n",
      "Train Loss: 0.0653, Train Accuracy: 74.18%\n",
      "Val Loss: 0.0669, Val Accuracy: 74.16%\n",
      "Epoch 90, Current LR: 0.000500\n",
      "Epoch 90/200\n",
      "Train Loss: 0.0656, Train Accuracy: 73.69%\n",
      "Val Loss: 0.0689, Val Accuracy: 72.05%\n",
      "Epoch 91, Current LR: 0.000500\n",
      "Epoch 91/200\n",
      "Train Loss: 0.0649, Train Accuracy: 74.39%\n",
      "Val Loss: 0.0671, Val Accuracy: 74.16%\n",
      "Epoch 92, Current LR: 0.000500\n",
      "Epoch 92/200\n",
      "Train Loss: 0.0649, Train Accuracy: 74.15%\n",
      "Val Loss: 0.0670, Val Accuracy: 74.79%\n",
      "Epoch 93, Current LR: 0.000500\n",
      "Epoch 93/200\n",
      "Train Loss: 0.0649, Train Accuracy: 74.20%\n",
      "Val Loss: 0.0673, Val Accuracy: 74.16%\n",
      "Epoch 94, Current LR: 0.000500\n",
      "Epoch 94/200\n",
      "Train Loss: 0.0651, Train Accuracy: 74.07%\n",
      "Val Loss: 0.0670, Val Accuracy: 75.00%\n",
      "Epoch 95, Current LR: 0.000500\n",
      "Epoch 95/200\n",
      "Train Loss: 0.0650, Train Accuracy: 73.94%\n",
      "Val Loss: 0.0671, Val Accuracy: 74.68%\n",
      "Epoch 96, Current LR: 0.000500\n",
      "Epoch 96/200\n",
      "Train Loss: 0.0653, Train Accuracy: 74.01%\n",
      "Val Loss: 0.0678, Val Accuracy: 73.31%\n",
      "Epoch 97, Current LR: 0.000500\n",
      "Epoch 97/200\n",
      "Train Loss: 0.0647, Train Accuracy: 74.18%\n",
      "Val Loss: 0.0670, Val Accuracy: 74.68%\n",
      "Epoch 98, Current LR: 0.000500\n",
      "Epoch 98/200\n",
      "Train Loss: 0.0643, Train Accuracy: 74.72%\n",
      "Val Loss: 0.0675, Val Accuracy: 73.52%\n",
      "Epoch 99, Current LR: 0.000500\n",
      "Epoch 99/200\n",
      "Train Loss: 0.0647, Train Accuracy: 74.16%\n",
      "Val Loss: 0.0671, Val Accuracy: 74.47%\n",
      "Epoch 100, Current LR: 0.000500\n",
      "Epoch 100/200\n",
      "Train Loss: 0.0648, Train Accuracy: 74.76%\n",
      "Val Loss: 0.0669, Val Accuracy: 74.68%\n",
      "Epoch 101, Current LR: 0.000500\n",
      "Epoch 101/200\n",
      "Train Loss: 0.0647, Train Accuracy: 74.72%\n",
      "Val Loss: 0.0673, Val Accuracy: 73.95%\n",
      "Epoch 102, Current LR: 0.000500\n",
      "Epoch 102/200\n",
      "Train Loss: 0.0645, Train Accuracy: 74.36%\n",
      "Val Loss: 0.0671, Val Accuracy: 74.05%\n",
      "Epoch 103, Current LR: 0.000500\n",
      "Epoch 103/200\n",
      "Train Loss: 0.0647, Train Accuracy: 74.18%\n",
      "Val Loss: 0.0679, Val Accuracy: 73.00%\n",
      "Epoch 104, Current LR: 0.000500\n",
      "Epoch 104/200\n",
      "Train Loss: 0.0651, Train Accuracy: 74.30%\n",
      "Val Loss: 0.0669, Val Accuracy: 74.26%\n",
      "Epoch 105, Current LR: 0.000500\n",
      "Epoch 105/200\n",
      "Train Loss: 0.0643, Train Accuracy: 74.28%\n",
      "Val Loss: 0.0675, Val Accuracy: 74.16%\n",
      "Epoch 106, Current LR: 0.000500\n",
      "Epoch 106/200\n",
      "Train Loss: 0.0648, Train Accuracy: 74.32%\n",
      "Val Loss: 0.0670, Val Accuracy: 74.16%\n",
      "Epoch 107, Current LR: 0.000500\n",
      "Epoch 107/200\n",
      "Train Loss: 0.0651, Train Accuracy: 74.24%\n",
      "Val Loss: 0.0669, Val Accuracy: 75.00%\n",
      "Epoch 108, Current LR: 0.000500\n",
      "Epoch 108/200\n",
      "Train Loss: 0.0647, Train Accuracy: 73.98%\n",
      "Val Loss: 0.0675, Val Accuracy: 74.89%\n",
      "Epoch 109, Current LR: 0.000500\n",
      "Epoch 109/200\n",
      "Train Loss: 0.0646, Train Accuracy: 74.24%\n",
      "Val Loss: 0.0669, Val Accuracy: 74.37%\n",
      "Epoch 110, Current LR: 0.000500\n",
      "Epoch 110/200\n",
      "Train Loss: 0.0648, Train Accuracy: 74.39%\n",
      "Val Loss: 0.0674, Val Accuracy: 73.63%\n",
      "Epoch 111, Current LR: 0.000500\n",
      "Epoch 111/200\n",
      "Train Loss: 0.0649, Train Accuracy: 74.28%\n",
      "Val Loss: 0.0674, Val Accuracy: 73.73%\n",
      "Epoch 112, Current LR: 0.000500\n",
      "Epoch 112/200\n",
      "Train Loss: 0.0645, Train Accuracy: 74.31%\n",
      "Val Loss: 0.0669, Val Accuracy: 74.16%\n",
      "Epoch 113, Current LR: 0.000500\n",
      "Epoch 113/200\n",
      "Train Loss: 0.0647, Train Accuracy: 74.48%\n",
      "Val Loss: 0.0673, Val Accuracy: 75.63%\n",
      "Epoch 114, Current LR: 0.000500\n",
      "Epoch 114/200\n",
      "Train Loss: 0.0650, Train Accuracy: 74.16%\n",
      "Val Loss: 0.0668, Val Accuracy: 75.42%\n",
      "Epoch 115, Current LR: 0.000500\n",
      "Epoch 115/200\n",
      "Train Loss: 0.0645, Train Accuracy: 74.63%\n",
      "Val Loss: 0.0671, Val Accuracy: 75.32%\n",
      "Epoch 116, Current LR: 0.000500\n",
      "Epoch 116/200\n",
      "Train Loss: 0.0646, Train Accuracy: 74.38%\n",
      "Val Loss: 0.0679, Val Accuracy: 73.21%\n",
      "Epoch 117, Current LR: 0.000500\n",
      "Epoch 117/200\n",
      "Train Loss: 0.0652, Train Accuracy: 73.75%\n",
      "Val Loss: 0.0672, Val Accuracy: 74.89%\n",
      "Epoch 118, Current LR: 0.000500\n",
      "Epoch 118/200\n",
      "Train Loss: 0.0649, Train Accuracy: 74.26%\n",
      "Val Loss: 0.0670, Val Accuracy: 74.37%\n",
      "Epoch 119, Current LR: 0.000500\n",
      "Epoch 119/200\n",
      "Train Loss: 0.0643, Train Accuracy: 74.51%\n",
      "Val Loss: 0.0671, Val Accuracy: 75.11%\n",
      "Epoch 120, Current LR: 0.000500\n",
      "Epoch 120/200\n",
      "Train Loss: 0.0646, Train Accuracy: 74.11%\n",
      "Val Loss: 0.0688, Val Accuracy: 72.15%\n",
      "Epoch 121, Current LR: 0.000500\n",
      "Epoch 121/200\n",
      "Train Loss: 0.0648, Train Accuracy: 73.78%\n",
      "Val Loss: 0.0670, Val Accuracy: 74.58%\n",
      "Epoch 122, Current LR: 0.000500\n",
      "Epoch 122/200\n",
      "Train Loss: 0.0643, Train Accuracy: 74.67%\n",
      "Val Loss: 0.0669, Val Accuracy: 75.00%\n",
      "Epoch 123, Current LR: 0.000500\n",
      "Epoch 123/200\n",
      "Train Loss: 0.0648, Train Accuracy: 74.34%\n",
      "Val Loss: 0.0691, Val Accuracy: 71.41%\n",
      "Epoch 124, Current LR: 0.000500\n",
      "Epoch 124/200\n",
      "Train Loss: 0.0642, Train Accuracy: 74.56%\n",
      "Val Loss: 0.0673, Val Accuracy: 74.47%\n",
      "Epoch 125, Current LR: 0.000500\n",
      "Epoch 125/200\n",
      "Train Loss: 0.0645, Train Accuracy: 74.58%\n",
      "Val Loss: 0.0677, Val Accuracy: 73.31%\n",
      "Epoch 126, Current LR: 0.000500\n",
      "Epoch 126/200\n",
      "Train Loss: 0.0648, Train Accuracy: 74.27%\n",
      "Val Loss: 0.0685, Val Accuracy: 71.84%\n",
      "Epoch 127, Current LR: 0.000500\n",
      "Epoch 127/200\n",
      "Train Loss: 0.0643, Train Accuracy: 74.39%\n",
      "Val Loss: 0.0672, Val Accuracy: 75.11%\n",
      "Epoch 128, Current LR: 0.000500\n",
      "Epoch 128/200\n",
      "Train Loss: 0.0647, Train Accuracy: 74.14%\n",
      "Val Loss: 0.0670, Val Accuracy: 74.79%\n",
      "Epoch 129, Current LR: 0.000500\n",
      "Epoch 129/200\n",
      "Train Loss: 0.0641, Train Accuracy: 74.38%\n",
      "Val Loss: 0.0672, Val Accuracy: 74.68%\n",
      "Epoch 130, Current LR: 0.000500\n",
      "Epoch 130/200\n",
      "Train Loss: 0.0644, Train Accuracy: 74.67%\n",
      "Val Loss: 0.0676, Val Accuracy: 74.16%\n",
      "Epoch 131, Current LR: 0.000500\n",
      "Epoch 131/200\n",
      "Train Loss: 0.0646, Train Accuracy: 74.48%\n",
      "Val Loss: 0.0675, Val Accuracy: 73.84%\n",
      "Epoch 132, Current LR: 0.000500\n",
      "Epoch 132/200\n",
      "Train Loss: 0.0643, Train Accuracy: 74.62%\n",
      "Val Loss: 0.0673, Val Accuracy: 73.95%\n",
      "Epoch 133, Current LR: 0.000500\n",
      "Epoch 133/200\n",
      "Train Loss: 0.0641, Train Accuracy: 74.40%\n",
      "Val Loss: 0.0670, Val Accuracy: 74.89%\n",
      "Epoch 134, Current LR: 0.000500\n",
      "Epoch 134/200\n",
      "Train Loss: 0.0645, Train Accuracy: 74.06%\n",
      "Val Loss: 0.0667, Val Accuracy: 74.89%\n",
      "Epoch 135, Current LR: 0.000500\n",
      "Epoch 135/200\n",
      "Train Loss: 0.0643, Train Accuracy: 74.48%\n",
      "Val Loss: 0.0672, Val Accuracy: 75.32%\n",
      "Epoch 136, Current LR: 0.000500\n",
      "Epoch 136/200\n",
      "Train Loss: 0.0643, Train Accuracy: 74.28%\n",
      "Val Loss: 0.0670, Val Accuracy: 74.26%\n",
      "Epoch 137, Current LR: 0.000500\n",
      "Epoch 137/200\n",
      "Train Loss: 0.0647, Train Accuracy: 74.48%\n",
      "Val Loss: 0.0676, Val Accuracy: 75.00%\n",
      "Epoch 138, Current LR: 0.000500\n",
      "Epoch 138/200\n",
      "Train Loss: 0.0645, Train Accuracy: 74.30%\n",
      "Val Loss: 0.0672, Val Accuracy: 74.89%\n",
      "Epoch 139, Current LR: 0.000500\n",
      "Epoch 139/200\n",
      "Train Loss: 0.0643, Train Accuracy: 74.75%\n",
      "Val Loss: 0.0673, Val Accuracy: 74.68%\n",
      "Epoch 140, Current LR: 0.000500\n",
      "Epoch 140/200\n",
      "Train Loss: 0.0643, Train Accuracy: 74.71%\n",
      "Val Loss: 0.0672, Val Accuracy: 73.73%\n",
      "Epoch 141, Current LR: 0.000500\n",
      "Epoch 141/200\n",
      "Train Loss: 0.0645, Train Accuracy: 74.39%\n",
      "Val Loss: 0.0669, Val Accuracy: 74.47%\n",
      "Epoch 142, Current LR: 0.000500\n",
      "Epoch 142/200\n",
      "Train Loss: 0.0643, Train Accuracy: 74.32%\n",
      "Val Loss: 0.0680, Val Accuracy: 73.00%\n",
      "Epoch 143, Current LR: 0.000500\n",
      "Epoch 143/200\n",
      "Train Loss: 0.0645, Train Accuracy: 74.30%\n",
      "Val Loss: 0.0673, Val Accuracy: 74.58%\n",
      "Epoch 144, Current LR: 0.000500\n",
      "Epoch 144/200\n",
      "Train Loss: 0.0645, Train Accuracy: 74.12%\n",
      "Val Loss: 0.0675, Val Accuracy: 74.37%\n",
      "Epoch 145, Current LR: 0.000500\n",
      "Epoch 145/200\n",
      "Train Loss: 0.0648, Train Accuracy: 74.07%\n",
      "Val Loss: 0.0676, Val Accuracy: 73.42%\n",
      "Epoch 146, Current LR: 0.000500\n",
      "Epoch 146/200\n",
      "Train Loss: 0.0644, Train Accuracy: 74.80%\n",
      "Val Loss: 0.0674, Val Accuracy: 73.52%\n",
      "Epoch 147, Current LR: 0.000500\n",
      "Epoch 147/200\n",
      "Train Loss: 0.0642, Train Accuracy: 74.76%\n",
      "Val Loss: 0.0670, Val Accuracy: 75.21%\n",
      "Epoch 148, Current LR: 0.000500\n",
      "Epoch 148/200\n",
      "Train Loss: 0.0642, Train Accuracy: 74.28%\n",
      "Val Loss: 0.0667, Val Accuracy: 75.11%\n",
      "Epoch 149, Current LR: 0.000500\n",
      "Epoch 149/200\n",
      "Train Loss: 0.0642, Train Accuracy: 74.43%\n",
      "Val Loss: 0.0674, Val Accuracy: 74.16%\n",
      "Epoch 150, Current LR: 0.000500\n",
      "Epoch 150/200\n",
      "Train Loss: 0.0642, Train Accuracy: 74.48%\n",
      "Val Loss: 0.0666, Val Accuracy: 75.11%\n",
      "Epoch 151, Current LR: 0.000500\n",
      "Epoch 151/200\n",
      "Train Loss: 0.0645, Train Accuracy: 74.39%\n",
      "Val Loss: 0.0669, Val Accuracy: 75.11%\n",
      "Epoch 152, Current LR: 0.000500\n",
      "Epoch 152/200\n",
      "Train Loss: 0.0639, Train Accuracy: 74.58%\n",
      "Val Loss: 0.0669, Val Accuracy: 74.68%\n",
      "Epoch 153, Current LR: 0.000500\n",
      "Epoch 153/200\n",
      "Train Loss: 0.0638, Train Accuracy: 74.87%\n",
      "Val Loss: 0.0676, Val Accuracy: 73.52%\n",
      "Epoch 154, Current LR: 0.000500\n",
      "Epoch 154/200\n",
      "Train Loss: 0.0639, Train Accuracy: 74.56%\n",
      "Val Loss: 0.0675, Val Accuracy: 73.73%\n",
      "Epoch 155, Current LR: 0.000500\n",
      "Epoch 155/200\n",
      "Train Loss: 0.0645, Train Accuracy: 74.55%\n",
      "Val Loss: 0.0670, Val Accuracy: 74.26%\n",
      "Epoch 156, Current LR: 0.000500\n",
      "Epoch 156/200\n",
      "Train Loss: 0.0643, Train Accuracy: 74.72%\n",
      "Val Loss: 0.0669, Val Accuracy: 75.32%\n",
      "Epoch 157, Current LR: 0.000500\n",
      "Epoch 157/200\n",
      "Train Loss: 0.0639, Train Accuracy: 74.55%\n",
      "Val Loss: 0.0669, Val Accuracy: 75.21%\n",
      "Epoch 158, Current LR: 0.000500\n",
      "Epoch 158/200\n",
      "Train Loss: 0.0644, Train Accuracy: 74.56%\n",
      "Val Loss: 0.0668, Val Accuracy: 75.32%\n",
      "Epoch 159, Current LR: 0.000500\n",
      "Epoch 159/200\n",
      "Train Loss: 0.0641, Train Accuracy: 74.44%\n",
      "Val Loss: 0.0668, Val Accuracy: 75.11%\n",
      "Epoch 160, Current LR: 0.000500\n",
      "Epoch 160/200\n",
      "Train Loss: 0.0641, Train Accuracy: 74.08%\n",
      "Val Loss: 0.0672, Val Accuracy: 74.68%\n",
      "Epoch 161, Current LR: 0.000500\n",
      "Epoch 161/200\n",
      "Train Loss: 0.0638, Train Accuracy: 74.59%\n",
      "Val Loss: 0.0669, Val Accuracy: 74.89%\n",
      "Epoch 162, Current LR: 0.000500\n",
      "Epoch 162/200\n",
      "Train Loss: 0.0641, Train Accuracy: 74.62%\n",
      "Val Loss: 0.0686, Val Accuracy: 71.94%\n",
      "Epoch 163, Current LR: 0.000500\n",
      "Epoch 163/200\n",
      "Train Loss: 0.0645, Train Accuracy: 74.10%\n",
      "Val Loss: 0.0672, Val Accuracy: 72.68%\n",
      "Epoch 164, Current LR: 0.000500\n",
      "Epoch 164/200\n",
      "Train Loss: 0.0644, Train Accuracy: 74.67%\n",
      "Val Loss: 0.0672, Val Accuracy: 75.21%\n",
      "Epoch 165, Current LR: 0.000500\n",
      "Epoch 165/200\n",
      "Train Loss: 0.0643, Train Accuracy: 74.64%\n",
      "Val Loss: 0.0679, Val Accuracy: 72.47%\n",
      "Epoch 166, Current LR: 0.000500\n",
      "Epoch 166/200\n",
      "Train Loss: 0.0639, Train Accuracy: 74.51%\n",
      "Val Loss: 0.0671, Val Accuracy: 74.79%\n",
      "Epoch 167, Current LR: 0.000500\n",
      "Epoch 167/200\n",
      "Train Loss: 0.0648, Train Accuracy: 74.77%\n",
      "Val Loss: 0.0676, Val Accuracy: 72.89%\n",
      "Epoch 168, Current LR: 0.000500\n",
      "Epoch 168/200\n",
      "Train Loss: 0.0639, Train Accuracy: 74.60%\n",
      "Val Loss: 0.0674, Val Accuracy: 74.05%\n",
      "Epoch 169, Current LR: 0.000500\n",
      "Epoch 169/200\n",
      "Train Loss: 0.0638, Train Accuracy: 74.62%\n",
      "Val Loss: 0.0678, Val Accuracy: 72.57%\n",
      "Epoch 170, Current LR: 0.000500\n",
      "Epoch 170/200\n",
      "Train Loss: 0.0644, Train Accuracy: 74.71%\n",
      "Val Loss: 0.0666, Val Accuracy: 75.11%\n",
      "Epoch 171, Current LR: 0.000500\n",
      "Epoch 171/200\n",
      "Train Loss: 0.0640, Train Accuracy: 74.67%\n",
      "Val Loss: 0.0673, Val Accuracy: 74.89%\n",
      "Epoch 172, Current LR: 0.000500\n",
      "Epoch 172/200\n",
      "Train Loss: 0.0642, Train Accuracy: 74.60%\n",
      "Val Loss: 0.0672, Val Accuracy: 74.79%\n",
      "Epoch 173, Current LR: 0.000500\n",
      "Epoch 173/200\n",
      "Train Loss: 0.0640, Train Accuracy: 74.66%\n",
      "Val Loss: 0.0667, Val Accuracy: 75.00%\n",
      "Epoch 174, Current LR: 0.000500\n",
      "Epoch 174/200\n",
      "Train Loss: 0.0642, Train Accuracy: 74.43%\n",
      "Val Loss: 0.0668, Val Accuracy: 75.11%\n",
      "Epoch 175, Current LR: 0.000500\n",
      "Epoch 175/200\n",
      "Train Loss: 0.0641, Train Accuracy: 74.14%\n",
      "Val Loss: 0.0670, Val Accuracy: 74.89%\n",
      "Epoch 176, Current LR: 0.000500\n",
      "Epoch 176/200\n",
      "Train Loss: 0.0642, Train Accuracy: 74.43%\n",
      "Val Loss: 0.0674, Val Accuracy: 73.52%\n",
      "Epoch 177, Current LR: 0.000500\n",
      "Epoch 177/200\n",
      "Train Loss: 0.0644, Train Accuracy: 74.60%\n",
      "Val Loss: 0.0665, Val Accuracy: 75.63%\n",
      "Epoch 178, Current LR: 0.000500\n",
      "Epoch 178/200\n",
      "Train Loss: 0.0641, Train Accuracy: 74.58%\n",
      "Val Loss: 0.0673, Val Accuracy: 74.79%\n",
      "Epoch 179, Current LR: 0.000500\n",
      "Epoch 179/200\n",
      "Train Loss: 0.0640, Train Accuracy: 74.76%\n",
      "Val Loss: 0.0665, Val Accuracy: 75.63%\n",
      "Epoch 180, Current LR: 0.000500\n",
      "Epoch 180/200\n",
      "Train Loss: 0.0639, Train Accuracy: 74.36%\n",
      "Val Loss: 0.0667, Val Accuracy: 75.42%\n",
      "Epoch 181, Current LR: 0.000500\n",
      "Epoch 181/200\n",
      "Train Loss: 0.0640, Train Accuracy: 74.42%\n",
      "Val Loss: 0.0684, Val Accuracy: 71.52%\n",
      "Epoch 182, Current LR: 0.000500\n",
      "Epoch 182/200\n",
      "Train Loss: 0.0638, Train Accuracy: 74.46%\n",
      "Val Loss: 0.0688, Val Accuracy: 71.73%\n",
      "Epoch 183, Current LR: 0.000500\n",
      "Epoch 183/200\n",
      "Train Loss: 0.0642, Train Accuracy: 74.40%\n",
      "Val Loss: 0.0665, Val Accuracy: 75.63%\n",
      "Epoch 184, Current LR: 0.000500\n",
      "Epoch 184/200\n",
      "Train Loss: 0.0634, Train Accuracy: 74.83%\n",
      "Val Loss: 0.0689, Val Accuracy: 71.41%\n",
      "Epoch 185, Current LR: 0.000500\n",
      "Epoch 185/200\n",
      "Train Loss: 0.0644, Train Accuracy: 74.27%\n",
      "Val Loss: 0.0668, Val Accuracy: 75.21%\n",
      "Epoch 186, Current LR: 0.000500\n",
      "Epoch 186/200\n",
      "Train Loss: 0.0639, Train Accuracy: 74.19%\n",
      "Val Loss: 0.0671, Val Accuracy: 74.16%\n",
      "Epoch 187, Current LR: 0.000500\n",
      "Epoch 187/200\n",
      "Train Loss: 0.0639, Train Accuracy: 74.63%\n",
      "Val Loss: 0.0672, Val Accuracy: 73.52%\n",
      "Epoch 188, Current LR: 0.000500\n",
      "Epoch 188/200\n",
      "Train Loss: 0.0640, Train Accuracy: 74.24%\n",
      "Val Loss: 0.0669, Val Accuracy: 74.26%\n",
      "Epoch 189, Current LR: 0.000500\n",
      "Epoch 189/200\n",
      "Train Loss: 0.0642, Train Accuracy: 74.34%\n",
      "Val Loss: 0.0674, Val Accuracy: 74.37%\n",
      "Epoch 190, Current LR: 0.000500\n",
      "Epoch 190/200\n",
      "Train Loss: 0.0639, Train Accuracy: 74.39%\n",
      "Val Loss: 0.0670, Val Accuracy: 74.05%\n",
      "Epoch 191, Current LR: 0.000500\n",
      "Epoch 191/200\n",
      "Train Loss: 0.0637, Train Accuracy: 74.36%\n",
      "Val Loss: 0.0668, Val Accuracy: 75.42%\n",
      "Epoch 192, Current LR: 0.000500\n",
      "Epoch 192/200\n",
      "Train Loss: 0.0641, Train Accuracy: 74.46%\n",
      "Val Loss: 0.0669, Val Accuracy: 75.21%\n",
      "Epoch 193, Current LR: 0.000500\n",
      "Epoch 193/200\n",
      "Train Loss: 0.0640, Train Accuracy: 74.73%\n",
      "Val Loss: 0.0683, Val Accuracy: 71.94%\n",
      "Epoch 194, Current LR: 0.000500\n",
      "Epoch 194/200\n",
      "Train Loss: 0.0638, Train Accuracy: 74.72%\n",
      "Val Loss: 0.0673, Val Accuracy: 74.58%\n",
      "Epoch 195, Current LR: 0.000500\n",
      "Epoch 195/200\n",
      "Train Loss: 0.0638, Train Accuracy: 74.55%\n",
      "Val Loss: 0.0669, Val Accuracy: 74.68%\n",
      "Epoch 196, Current LR: 0.000500\n",
      "Epoch 196/200\n",
      "Train Loss: 0.0637, Train Accuracy: 74.76%\n",
      "Val Loss: 0.0687, Val Accuracy: 72.36%\n",
      "Epoch 197, Current LR: 0.000500\n",
      "Epoch 197/200\n",
      "Train Loss: 0.0640, Train Accuracy: 74.77%\n",
      "Val Loss: 0.0674, Val Accuracy: 74.05%\n",
      "Epoch 198, Current LR: 0.000500\n",
      "Epoch 198/200\n",
      "Train Loss: 0.0639, Train Accuracy: 74.68%\n",
      "Val Loss: 0.0670, Val Accuracy: 74.68%\n",
      "Epoch 199, Current LR: 0.000500\n",
      "Epoch 199/200\n",
      "Train Loss: 0.0637, Train Accuracy: 74.99%\n",
      "Val Loss: 0.0686, Val Accuracy: 71.73%\n",
      "Epoch 200, Current LR: 0.000500\n",
      "Epoch 200/200\n",
      "Train Loss: 0.0642, Train Accuracy: 74.54%\n",
      "Val Loss: 0.0668, Val Accuracy: 74.26%\n",
      "模型已保存\n",
      "最小测试损失 0.0665 出现在第 183 轮\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from Model import ConvAndAttentionModel\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('PDF')\n",
    "import matplotlib.pyplot as plt\n",
    "from FocalLoss import FocalLoss\n",
    "from sklearn.utils import class_weight\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "parameter='alpha5'\n",
    "change_dir='P'\n",
    "base_dir=f'/home/ykq/projects/CPSC0926/mouse/train/{change_dir}/traindata/'\n",
    "if not os.path.exists(base_dir+'scaler'):\n",
    "    os.makedirs(base_dir+'scaler', exist_ok=True)\n",
    "    os.makedirs(base_dir+'picture', exist_ok=True)\n",
    "    os.makedirs(base_dir+'predict_test', exist_ok=True)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)  # 转换为 Tensor\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)  # 转换为 Tensor (分类)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "def load_data(data_file, labels_file):\n",
    "    \"\"\"\n",
    "    加载 .npz 文件中的数据和标签。\n",
    "    \"\"\"\n",
    "    data = np.load(data_file)['data']\n",
    "    labels = np.load(labels_file)['labels']\n",
    "    return data, labels\n",
    "\n",
    "def process_features_norm(features):\n",
    "    n_samples, n_timesteps, n_features = features.shape\n",
    "    # 创建拷贝，避免修改原始数据\n",
    "    scaled_features = features.copy()\n",
    "    # print(scaler_metrics)\n",
    "    for feature_idx in range(n_features):\n",
    "        if feature_idx == 2:\n",
    "            # 提取当前特征的所有数据\n",
    "            # 形状变为 (100 * 19, 1)\n",
    "            feature_column = scaled_features[:, :, feature_idx].reshape(-1, 1)\n",
    "            # 取对数\n",
    "            feature_column = np.log1p(feature_column)\n",
    "\n",
    "            minmax_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "            normalized_results = minmax_scaler.fit_transform(feature_column)\n",
    "\n",
    "            scaled_features[:, :, feature_idx] = normalized_results.reshape((n_samples, n_timesteps))\n",
    "\n",
    "    return scaled_features\n",
    "\n",
    "\n",
    "def process_features(features):\n",
    "    n_samples, n_timesteps, n_features = features.shape\n",
    "    # 创建拷贝\n",
    "    scaled_features = features.copy()\n",
    "    scaler_metrics = np.zeros((n_features, 4))\n",
    "    # print(scaler_metrics)\n",
    "    for feature_idx in range(n_features):\n",
    "        # 提取当前特征的所有数据\n",
    "        feature_column = features[:, :, feature_idx].reshape(-1, 1)\n",
    "        # 标准化处理\n",
    "        std_scaler = StandardScaler()\n",
    "        std_results = std_scaler.fit_transform(feature_column)\n",
    "        scaler_metrics[feature_idx, 0] = std_scaler.mean_[0]\n",
    "        scaler_metrics[feature_idx, 1] = std_scaler.scale_[0]\n",
    "        minmax_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        normalized_results = minmax_scaler.fit_transform(std_results)\n",
    "        scaler_metrics[feature_idx, 2] = minmax_scaler.min_[0]\n",
    "        scaler_metrics[feature_idx, 3] = minmax_scaler.scale_[0]\n",
    "        scaled_features[:, :, feature_idx] = normalized_results.reshape((n_samples, n_timesteps))\n",
    "        # 保存\n",
    "    with open(f'/home/ykq/projects/CPSC0926/mouse/train/{change_dir}/traindata/scaler/scaler_metrics_V2.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler_metrics, f)\n",
    "    return scaled_features\n",
    "\n",
    "\n",
    "def process_features_predict(features):\n",
    "    with open(f'/home/ykq/projects/CPSC0926/mouse/train/{change_dir}/traindata/scaler/scaler_metrics_V2.pkl', 'rb') as f:\n",
    "        scaler_metrics = pickle.load(f)\n",
    "    n_samples, n_timesteps, n_features = features.shape\n",
    "    # 创建拷贝\n",
    "    scaled_features = features.copy()\n",
    "    for feature_idx in range(n_features):\n",
    "        # 提取当前特征的所有数据\n",
    "        feature_column = scaled_features[:, :, feature_idx].reshape(-1, 1)\n",
    "        stdmean = scaler_metrics[feature_idx, 0]\n",
    "        stdscale = scaler_metrics[feature_idx, 1]\n",
    "        feature_column -= stdmean\n",
    "        feature_column /= stdscale\n",
    "        minmaxmin = scaler_metrics[feature_idx, 2]\n",
    "        minmaxscale = scaler_metrics[feature_idx, 3]\n",
    "        feature_column *= minmaxscale\n",
    "        feature_column += minmaxmin\n",
    "        clipped_data = np.clip(feature_column, -1, 1)\n",
    "        scaled_features[:, :, feature_idx] = clipped_data.reshape((n_samples, n_timesteps))\n",
    "    return scaled_features\n",
    "\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()  # 模型设置为训练模式\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_data, batch_labels in train_loader:\n",
    "        # 将数据传输到 GPU\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        # 前向传播\n",
    "        outputs = model(batch_data)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 计算损失和准确率\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += batch_labels.size(0)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return running_loss / len(train_loader), accuracy\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device, threshold=0.5, return_preds=False):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    if return_preds:\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in val_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            val_loss += loss.item()\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            predicted = (probs[:, 1] >= threshold).long()\n",
    "            total += batch_labels.size(0)\n",
    "            correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "            if return_preds:\n",
    "                # 注意：这里我们用 .append() 来添加整个批次的数据\n",
    "                all_labels.append(batch_labels.cpu().numpy())\n",
    "                all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "\n",
    "    if return_preds:\n",
    "        # 在函数返回前，直接进行拼接\n",
    "        final_labels = np.concatenate(all_labels, axis=0)\n",
    "        final_probs = np.concatenate(all_probs, axis=0)\n",
    "        return val_loss / len(val_loader), accuracy, final_labels, final_probs\n",
    "    else:\n",
    "        return val_loss / len(val_loader), accuracy\n",
    "\n",
    "    # 根据请求返回不同的结果\n",
    "    if return_preds:\n",
    "        return val_loss / len(val_loader), accuracy, all_labels, all_probs\n",
    "    else:\n",
    "        return val_loss / len(val_loader), accuracy\n",
    "\n",
    "\n",
    "def plot_loss_and_accuracy(train_losses, val_losses, train_accuracies, val_accuracies, num_epochs, work_dic):\n",
    "    \"\"\"\n",
    "    绘制损失率和准确率曲线\n",
    "    \"\"\"\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    # 创建一个带有损失和准确率的双子图\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    # 绘制损失曲线\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label='Train Loss')\n",
    "    plt.plot(epochs, val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.legend()\n",
    "    # 绘制准确率曲线\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(epochs, val_accuracies, label='Val Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.ylim(0, 100)  # 限定准确率区间为 0% ~ 100%\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "    # 显示图像\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(work_dic + f'picture/ACC{parameter}.pdf', format='pdf')\n",
    "\n",
    "\n",
    "def plot_roc_curve(labels, probs, work_dic):\n",
    "    \"\"\"\n",
    "    绘制 ROC 曲线并计算 AUC 值\n",
    "    \"\"\"\n",
    "    # 将多分类问题转化为二分类问题（One-vs-Rest）\n",
    "    fpr, tpr, _ = roc_curve(labels, probs[:, 1])  # 假设正类是第 1 类\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # 绘制 ROC 曲线\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(work_dic + f'picture/ROC{parameter}.pdf', format='pdf')\n",
    "\n",
    "\n",
    "def plot_pr_curve(labels, probs, work_dic):\n",
    "    \"\"\"\n",
    "    绘制 Precision-Recall 曲线并计算 AP 值\n",
    "    \"\"\"\n",
    "    # 假设是二分类问题，取正类概率\n",
    "    precision, recall, _ = precision_recall_curve(labels, probs[:, 1])\n",
    "    avg_precision = average_precision_score(labels, probs[:, 1])\n",
    "    # 绘制 PR 曲线\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}')\n",
    "    plt.plot([0, 1], [1, 0], 'k--', label='Random Guess')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.savefig(work_dic + f'picture/PR{parameter}.pdf', format='pdf')\n",
    "\n",
    "\n",
    "work_dic = f'/home/ykq/projects/CPSC0926/mouse/train/{change_dir}/traindata/'\n",
    "data_dic = f'/home/ykq/projects/CPSC0926/mouse/train/{change_dir}/traindata/'\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 加载训练、验证、测试集\n",
    "    train_data, train_labels = load_data(data_dic + '/equaltrain_data.npz', data_dic + '/equaltrain_labels.npz')\n",
    "    val_data, val_labels = load_data(data_dic + '/val_data.npz', data_dic + '/val_labels.npz')\n",
    "    test_data, test_labels = load_data(data_dic + '/test_data.npz', data_dic + '/test_labels.npz')\n",
    "    # 先对atac做归一化\n",
    "    train_data_Norm = process_features_norm(train_data)\n",
    "    val_data_Norm = process_features_norm(val_data)\n",
    "    test_data_Norm = process_features_norm(test_data)\n",
    "\n",
    "    # 处理数据\n",
    "    train_data_scaled = process_features(train_data_Norm)\n",
    "    val_data_scaled = process_features_predict(val_data_Norm)\n",
    "    test_data_scaled = process_features_predict(test_data_Norm)\n",
    "\n",
    "    # 创建 PyTorch 的 Dataset\n",
    "    train_dataset = CustomDataset(train_data_scaled, train_labels)\n",
    "    val_dataset = CustomDataset(val_data_scaled, val_labels)\n",
    "    test_dataset = CustomDataset(test_data_scaled, test_labels)\n",
    "    # 创建 Dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "    # model_V2\n",
    "    first_conv_out_channels = 32\n",
    "    first_kernel_size = (2, 24)\n",
    "    second_conv_out_channels = 64\n",
    "    second_kernel_size = (2, 32)\n",
    "    attention_output_dim = 16  # V 的行数\n",
    "    maxpool_kernel_size = 16\n",
    "    model = ConvAndAttentionModel(\n",
    "        first_conv_out_channels=first_conv_out_channels,\n",
    "        first_kernel_size=first_kernel_size,\n",
    "        second_conv_out_channels=second_conv_out_channels,\n",
    "        second_kernel_size=second_kernel_size,\n",
    "        attention_output_dim=attention_output_dim,\n",
    "        maxpool_kernel_size=maxpool_kernel_size)\n",
    "    # 直接使用labels\n",
    "    ground_truth = train_labels  # 假设labels已经是类别索引\n",
    "    # 计算类别权重\n",
    "    unique_classes = np.unique(ground_truth)\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                      classes=unique_classes,\n",
    "                                                      y=ground_truth)\n",
    "    # # 将模型移动到 GPU（如果可用）\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #\n",
    "    weights = torch.FloatTensor(class_weights).to(device)\n",
    "    # 创建 Loss\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    # default Parameters: alpha=0.6,gamma=2,lr=0.0005)\n",
    "    criterion = FocalLoss(alpha=0.5, gamma=2, weight=weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "    # 学习率调度器\n",
    "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "    model.to(device)\n",
    "    num_epochs = 200\n",
    "    # 用于记录训练过程中的损失和准确率\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    min_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        #scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'Epoch {epoch + 1}, Current LR: {current_lr:.6f}')\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        # 记录损失和准确率\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%\")\n",
    "        # 更新最小测试损失\n",
    "        if val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "        #每10个epoch保存一次模型（新增逻辑）\n",
    "        # if (epoch + 1) % 10 == 0:  # epoch从0开始计数，所以+1\n",
    "        #     periodic_save_path = f\"{data_dic}/model_every10epoch/P_default_V2_epoch{epoch + 1}.pth\"\n",
    "        #     torch.save(model.state_dict(), periodic_save_path)\n",
    "        #     print(f\"Periodic model saved at epoch {epoch + 1}\")\n",
    "    print(f\"模型已保存\")\n",
    "    print(f\"最小测试损失 {min_val_loss:.4f} 出现在第 {best_epoch} 轮\")\n",
    "    model_save_path = f\"{data_dic}/Model_V2_epoch{best_epoch}_{parameter}.pth\"\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "\n",
    "    # 绘制训练过程中的损失和准确率曲线\n",
    "    plot_loss_and_accuracy(train_losses, val_losses, train_accuracies, val_accuracies, num_epochs, work_dic)\n",
    "    # 进行测试集的预测\n",
    "    best_model = ConvAndAttentionModel(\n",
    "        first_conv_out_channels=first_conv_out_channels,\n",
    "        first_kernel_size=first_kernel_size,\n",
    "        second_conv_out_channels=second_conv_out_channels,\n",
    "        second_kernel_size=second_kernel_size,\n",
    "        attention_output_dim=attention_output_dim,\n",
    "        maxpool_kernel_size=maxpool_kernel_size\n",
    "    )\n",
    "    best_model.load_state_dict(torch.load(model_save_path, weights_only=True))\n",
    "    best_model.to(device)\n",
    "    '''\n",
    "    使用我们优化后的evaluate函数，一行代码完成所有预测和结果收集\n",
    "    注意：我们不需要 best_model.eval()，因为函数内部已经设置了\n",
    "    我们也不需要 test_loss 和 test_acc，所以可以用 _ 来忽略它们\n",
    "    '''\n",
    "    _, _, test_true_labels, test_probs = evaluate(best_model, test_loader, criterion, device, return_preds=True)\n",
    "    \n",
    "    np.save(work_dic + f'/predict_test/test_probs{parameter}.npy', test_probs)\n",
    "    np.save(work_dic + f'/predict_test/test_labels{parameter}.npy', test_true_labels)\n",
    "    # 绘制 ROC&PR 曲线\n",
    "    plot_roc_curve(test_true_labels, test_probs, work_dic)\n",
    "    plot_pr_curve(test_true_labels, test_probs, work_dic)\n",
    "\n",
    "    test_pred_labels = np.argmax(test_probs, axis=1)\n",
    "\n",
    "    # 生成混淆矩阵\n",
    "    cm = confusion_matrix(test_true_labels, test_pred_labels)\n",
    "\n",
    "    # 绘制混淆矩阵\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Class 0', 'Class 1'],\n",
    "                yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(work_dic + f'picture/confusion_matrix{parameter}.pdf', format='pdf')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaa9dee-bcc9-42ff-a001-77a2b5c81c60",
   "metadata": {},
   "source": [
    "## 运行完上述代码之后，去/home/ykq/projects/CPSC0926/mouse/train/traindata文件夹下面检查是否有picture等文件夹，有则进行下一步"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8cdf0e-1cc3-490a-865d-e09bc282db94",
   "metadata": {},
   "source": [
    "## 画模型的roc，pr以及混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "314ee950-54f5-45f6-b62d-eb233e7e7c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "def load_data(prob_path):\n",
    "    \"\"\"加载概率文件和标签文件\"\"\"\n",
    "    label_path = prob_path.replace('probs', 'labels')\n",
    "    y_prob = np.load(prob_path)\n",
    "    y_true = np.load(label_path)\n",
    "    # 如果输出多列概率，取正类的概率\n",
    "    if y_prob.ndim > 1 and y_prob.shape[1] > 1:\n",
    "        y_prob = y_prob[:, 1]\n",
    "    return y_true, y_prob\n",
    "\n",
    "def plot_roc(y_true, y_prob, color, label_text, filename):\n",
    "    \"\"\"计算并绘制 ROC 曲线\"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    auc_value = roc_auc_score(y_true, y_prob)\n",
    "    plt.figure(figsize=(6, 5),dpi=300)\n",
    "    plt.plot(fpr, tpr, color=color, lw=2, label=f'{label_text} (AUC = {auc_value:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.title('ROC Curve', fontsize=20)\n",
    "    plt.legend(loc=\"lower right\", fontsize=12, frameon=False)\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, format='pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_pr(y_true, y_prob, color, label_text, filename):\n",
    "    \"\"\"计算并绘制 PR 曲线\"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "    avg_precision = np.mean(precision)\n",
    "    plt.figure(figsize=(6, 5),dpi=300)\n",
    "    plt.plot(recall, precision, color=color, lw=2, label=f'{label_text} (AP = {avg_precision:.2f})')\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('Recall', fontsize=18)\n",
    "    plt.ylabel('Precision', fontsize=18)\n",
    "    plt.title('PR Curve', fontsize=20)\n",
    "    plt.legend(loc=\"lower left\", fontsize=12, frameon=False)\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, format='pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_prob, filename):\n",
    "    \"\"\"绘制阈值下的混淆矩阵\"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(6, 5), dpi=300)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix\\n (Threshold = {optimal_threshold:.2f})', fontsize=20)\n",
    "    plt.xlabel('Predicted', fontsize=18)\n",
    "    plt.ylabel('Actual', fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, format='pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 文件路径\n",
    "prob_file_old = '/home/ykq/projects/CPSC0926/mouse/train/P/traindata/predict_test/test_probsalpha5.npy'\n",
    "\n",
    "# 加载数据\n",
    "y_true_old, y_prob_old = load_data(prob_file_old)\n",
    "\n",
    "# 绘制并保存 GM12878 valid 的 ROC 曲线\n",
    "plot_roc(y_true_old, y_prob_old, color='purple', label_text='Mouse CD8+ test', filename='/home/ykq/projects/CPSC0926/fig/mouse_valid_roc.pdf')\n",
    "\n",
    "# 绘制并保存 GM12878 valid 的 PR 曲线\n",
    "plot_pr(y_true_old, y_prob_old, color='purple', label_text='Mouse CD8+ test', filename='/home/ykq/projects/CPSC0926/fig/mouse_valid_pr.pdf')\n",
    "\n",
    "# 绘制并保存 GM12878 valid 的混淆矩阵\n",
    "plot_confusion_matrix(y_true_old, y_prob_old, filename='/home/ykq/projects/CPSC0926/fig/mouse_valid_confusion_matrix.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
